import { NextRequest } from 'next/server'
import OpenAI from 'openai'

// Configuration OpenAI
const OPENAI_API_KEY = process.env.OPENAI_API_KEY
const openai = OPENAI_API_KEY ? new OpenAI({ apiKey: OPENAI_API_KEY }) : null

console.log('ü§ñ [Chat API Config]', openai ? '‚úÖ OPENAI GPT-4 ACTIV√â' : '‚ö†Ô∏è MODE D√âMO')

// Prompt syst√®me pour le chatbot
const SYSTEM_PROMPT = `Tu es un expert en r√©novation sympathique et professionnel sur SimuTravaux.

IMPORTANT - Pose UNE question √† la fois, naturellement.

Types de travaux support√©s : cuisine, salle de bain, peinture, sol/parquet, √©lectricit√©, plomberie, chauffage, fen√™tres/portes, isolation, toiture, extension, r√©novation compl√®te.

Processus :
1. Type de travaux
2. Surface en m¬≤
3. Qualit√© (pr√©sente les 3 options avec prix AVANT de demander) :
   - √âconomique (calcul : surface √ó prix/m¬≤ √ó 0.8)
   - Standard (calcul : surface √ó prix/m¬≤)
   - Premium (calcul : surface √ó prix/m¬≤ √ó 1.3)
4. Code postal

Estimation COMPACTE (max 15 lignes) :
üí∞ Budget (Qualit√©) : min - moyen - max
üìä MO (55%) / Mat√©riaux (35%) / Finitions (10%)
‚è± D√©lai | üìç CP (+X%) | ‚öôÔ∏è Complexit√©
üîß 2-3 conseils techniques
‚öñÔ∏è 2-3 normes
üé® 2-3 tendances 2025
üí° 3 devis, assurances, +15%
üí∏ Aides disponibles

Sois chaleureux, concis. PAS de markdown. √âvite r√©p√©titions.`

// Fonction de d√©mo (backup si pas de cl√© OpenAI)
function generateDemoResponse(messages: any[]): string {
  const lastMessage = messages[messages.length - 1]?.content?.toLowerCase() || ''
  
  // D√©tection des informations
  const surfaceMatch = lastMessage.match(/(\d{1,4})\s*(?:m2|m¬≤|metre|m√®tre)/i)
  const postalMatch = lastMessage.match(/\b(\d{5})\b/)
  
  // Message de bienvenue
  if (messages.length === 1) {
    return "Bonjour ! Je suis votre assistant r√©novation. Quel type de travaux souhaitez-vous r√©aliser ? (cuisine, salle de bain, peinture, etc.)"
  }
  
  // Logique simplifi√©e
  if (lastMessage.includes('cuisine')) {
    return "Parfait ! Quelle est la surface de votre cuisine en m¬≤ ?"
  }
  
  if (surfaceMatch) {
    const surface = parseInt(surfaceMatch[1])
    return `D'accord, ${surface}m¬≤. Quelle qualit√© de finition souhaitez-vous ?\n\n‚Ä¢ √âconomique (~400‚Ç¨/m¬≤)\n‚Ä¢ Standard (~600‚Ç¨/m¬≤)\n‚Ä¢ Premium (~900‚Ç¨/m¬≤)`
  }
  
  if (lastMessage.includes('standard') || lastMessage.includes('premium') || lastMessage.includes('√©conomique')) {
    return "Excellent choix ! Quel est votre code postal pour affiner l'estimation ?"
  }
  
  if (postalMatch) {
    return `üí∞ Budget estim√© : 8 000 ‚Ç¨ - 12 000 ‚Ç¨ - 18 000 ‚Ç¨\nüìä Main d'≈ìuvre 55% | Mat√©riaux 35% | Finitions 10%\n‚è± D√©lai : 3-4 semaines\nüîß Conseils : Comparez 3 devis, pr√©voirez +15%`
  }
  
  return "Je n'ai pas bien compris. Pouvez-vous pr√©ciser votre projet de r√©novation ?"
}

export async function POST(request: NextRequest) {
  console.log('üîµ [Chat API] Requ√™te re√ßue')
  const encoder = new TextEncoder()

  const stream = new ReadableStream({
    async start(controller) {
      try {
        const body = await request.json()
        const { messages } = body

        console.log('üì© [Chat API] Messages re√ßus:', messages?.length)

        if (!messages || messages.length === 0) {
          controller.enqueue(
            encoder.encode(`data: ${JSON.stringify({ text: 'Aucun message re√ßu' })}\n\n`)
          )
          controller.close()
          return
        }

        // Mode OpenAI GPT-4
        if (openai) {
          console.log('‚úÖ [OpenAI] Appel √† GPT-4o...')
          
          const completion = await openai.chat.completions.create({
            model: 'gpt-4o',
            messages: [
              { role: 'system', content: SYSTEM_PROMPT },
              ...messages.map((m: any) => ({
                role: m.role,
                content: m.content,
              })),
            ],
            temperature: 0.7,
            max_tokens: 500,
            stream: true,
          })

          console.log('üì° [OpenAI] Stream d√©marr√©')

          for await (const chunk of completion) {
            const content = chunk.choices[0]?.delta?.content
            if (content) {
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify({ text: content })}\n\n`)
              )
            }
          }

          console.log('‚úÖ [OpenAI] R√©ponse compl√®te')
        } else {
          // Mode d√©mo
          console.log('üéØ [Demo Mode] G√©n√©ration de r√©ponse...')
          const response = generateDemoResponse(messages)
          
          // Simuler un stream
          for (let i = 0; i < response.length; i += 5) {
            const chunk = response.slice(i, i + 5)
            controller.enqueue(
              encoder.encode(`data: ${JSON.stringify({ text: chunk })}\n\n`)
            )
            await new Promise(resolve => setTimeout(resolve, 20))
          }
          
          console.log('‚úÖ [Demo] R√©ponse envoy√©e')
        }

        controller.close()
      } catch (error: any) {
        console.error('‚ùå [Chat API] ERREUR:', error)
        controller.enqueue(
          encoder.encode(
            `data: ${JSON.stringify({ 
              error: `Erreur: ${error.message || 'Une erreur est survenue'}` 
            })}\n\n`
          )
        )
        controller.close()
      }
    },
  })

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
    },
  })
}
